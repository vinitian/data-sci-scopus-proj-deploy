{
    "eid": "2-s2.0-84957837511",
    "title": "Human action classification using adaptive key frame interval for feature extraction",
    "cover-date": "2016-01-01",
    "subject-areas": [
        {
            "$": "Electrical and Electronic Engineering",
            "@code": "2208"
        },
        {
            "$": "Computer Science Applications",
            "@code": "1706"
        },
        {
            "$": "Atomic and Molecular Physics",
            "@code": "3107"
        }
    ],
    "keywords": [
        "action classification",
        "adaptive motion history image",
        "human posture",
        "key frame"
    ],
    "authors": [
        "Kanokphan Lertniphonphan"
    ],
    "citedby-count": 4,
    "ref-count": 52,
    "ref-list": [
        "A survey on visual surveillance of object motion and behaviors",
        "The visual analysis of human movement: A survey",
        "A survey on vision-based human action recognition",
        "Human activity analysis: A review",
        "Fast human activity recognition based on structure and motion",
        "Silhouette-based human action recognition using sequences of key poses",
        "Histogram of oriented rectangles: A new pose descriptor for human action recognition",
        "Actions as space-time shapes",
        "Slow feature analysis for human action recognition",
        "3D Convolutional neural networks for human action recognition",
        "Motion segmentation and pose recognition with motion history gradients",
        "The recognition of human movement using temporal templates",
        "Hierarchical filtered motion for action recognition in crowded videos",
        "Action Snippets: How many frames does human action recognition require?",
        "Histograms of optical flow for efficient representation of body motion",
        "Event semantics in two-person interactions",
        "Human behavior recognition using a context-free grammar",
        "Individual recognition using gait energy image",
        "Recognizing human actions using key poses",
        "Poselet key-framing: A model for human activity recognition",
        "Human action recognition based on spatial-temporal descriptors using key poses",
        "Visual motion and the neural correlates of event perception",
        "Activation of human motion processing areas during event perception",
        "Robust real-time periodic motion detection, analysis, and applications",
        "Histograms of oriented optical flow and Binet-Cauchy kernels on nonlinear dynamical systems for the recognition of human actions",
        "Action recognition in broadcast tennis video using optical flow and support vector machine",
        "Human action recognition based on aggregated local motion estimates",
        "Recognising and monitoring high-level behaviours in complex spatial environments",
        "Activity recognition and abnormality detection with the switching hidden semi-Markov model",
        "Recognizing human actions by learning and matching shape-motion prototype trees",
        "Recognizing action at a distance",
        "Histograms of oriented gradients for human detection",
        "Object motion detection using information theoretic spatio-temporal saliency",
        "Human action recognition in videos using kinematic features and multiple instance learning",
        "Space-time behavior based correlation",
        "Space-time interest points",
        "Proc. of the Alvey Vision Conf.",
        "Action recognition using mined hierarchical compound features",
        "Behavior recognition via sparse spatio-temporal features",
        "Unsupervised learning of human action categories using spatial-temporal words",
        "Action recognition using spatiotemporal features and hybrid generative/discriminative models",
        "Manifold-constrained coding and sparse representation for human action recognition",
        "Motion history image: Its variants and applications",
        "Proc. of Int. Workshop on Smart Info-Media System in Asia",
        "Recognizing human actions: A local SVM approach",
        "UT-interaction Dataset, ICPR Contest on Semantic Description of Human Activities (SDHA)",
        "A hierarchical model of shape and appearance for human action classification",
        "Pose primitive based human action recognition in videos or still images",
        "Spatio-temporal relationship match: Video structure comparison for recognition of complex human activities",
        "Real-time action recognition by spatiotemporal semantic and structural forests",
        "Middle-level representation for human activities recognition: The role of spatio-temporal relationships",
        "Recognizing interaction between human performers using'key pose doublet'"
    ],
    "affiliation": {
        "affiliation-city": "Bangkok",
        "affilname": "Chulalongkorn University",
        "affiliation-country": "Thailand"
    },
    "funding": []
}