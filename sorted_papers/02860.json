{
    "eid": "2-s2.0-85074226436",
    "title": "Classification of Anger Voice in Call Center Dialog",
    "cover-date": "2019-07-01",
    "subject-areas": [
        {
            "@_fa": "true",
            "$": "Artificial Intelligence",
            "@code": "1702",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Computer Networks and Communications",
            "@code": "1705",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Human-Computer Interaction",
            "@code": "1709",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Signal Processing",
            "@code": "1711",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Software",
            "@code": "1712",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Information Systems and Management",
            "@code": "1802",
            "@abbrev": "DECI"
        }
    ],
    "keywords": [
        "Anger Detection",
        "Call center conversation",
        "component",
        "Emotion Recognition",
        "Machine Learning"
    ],
    "authors": [
        "Widakorn Saewong",
        "Janjao Mongkolnavin"
    ],
    "citedby-count": 3,
    "ref-count": 31,
    "ref-list": [
        "Hybrid approach for emotion classification of audio conversation based on text and speech mining",
        "Mining call center conversations exhibiting similar affective states paper presented at the proceedings of the 30th pacific Asia conference on language",
        "An Articulatory-Based Singing Voice Synthesis Using Tongue and Lips Imaging Paper presented at the ISCA Interspeech 2016",
        "Hidden Markov Model Based Speech Synthesis",
        "Deep Neural Network Approaches to Speaker and Language Recognition",
        "Detecting Real Life Anger Paper presented at the 2009 IEEE",
        "Emotion Recognition in Spontaneous and Acted Dialogues",
        "Spontaneous Speech Emotion Recognition Using Prior Knowledge Paper presented at the 2016",
        "Survey on Audiovisual Emotion Recognition: Databases, Features, and Data Fusion Strategies",
        "Av Ec 2015: The First Affect Recognition Challenge Bridging across Audio, Video, and Physiological Data",
        "Emotion Recognition in Spontaneous and Acted Dialogues",
        "Speaker-Sensitive Emotion Recognition Via Ranking: Studies on Acted and Spontaneous Speech",
        "Speech-Based Recognition of Self-Reported and Observed Emotion in a Dimensional Space",
        "Emotion recognition from speech via boosted Gaussian mixture models paper presented at the 2009 ieee",
        "A database of German emotional speech",
        "Audio-Visual Feature Selection and Reduction for Emotion Classification",
        "Time-Frequency Feature Representation Using Multi-Resolution Texture Analysis and Acoustic Activity Detector for Real-Life Speech Emotion Recognition",
        "Emotional States Discrimination in Voice in Secure Environments Paper presented at the 2015",
        "Survey on speech emotion recognition: Features, classification schemes, and databases",
        "Feature Extraction Methods Lpc",
        "Toward the Simulation of Emotion in Synthetic Speech",
        "Vocal Expression and Communication of Emotion",
        "Self-Consciousness and Emotional Expression",
        "The Interspeech 2010 Paralinguistic Challenge",
        "Emotion Recognition from Speech Signal",
        "Emotion Challenge feature set (IS): Low-level descriptors (LLD) and functionals"
    ],
    "affiliation": {
        "affiliation-city": "Bangkok",
        "@id": "60028190",
        "affilname": "Chulalongkorn University",
        "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190",
        "affiliation-country": "Thailand"
    },
    "funding": []
}